{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "f202707d",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#IMPORTAMOS LAS LIBRERIAS BASADAS EN TENSORFLOW Y KERAS\n",
    "import sys\n",
    "import os\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras import optimizers\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dropout, Flatten, Dense, Activation\n",
    "from tensorflow.keras.layers import  Convolution2D, MaxPooling2D\n",
    "from tensorflow.keras import backend as K\n",
    "\n",
    "#LIMPIAMOS SESIN DE KERAS PARA EMPEZAR DESDE 0 EN MEMORIA\n",
    "K.clear_session()\n",
    "#GENERAMOS 2 VARIABLES CON CADA UNA DE LAS CARPETAS TANTO DE ENTRENAMIENTO COMO DE TEST CON FOTOGRAFIAS\n",
    "data_entrenamiento = './CarneDataset/train'\n",
    "data_validacion = './CarneDataset/test'\n",
    "#DECLARACION DE VARIABLES CON VALORES QUE PARAMETRIZARAN EL DESEMPEÑO DEL ENTRENAMIENTO DEL MODELO DE CLASIFICACION DE FOTOS\n",
    "epocas=15 #NUMERO DE EPOCHS PARA EL TRAINING\n",
    "longitud, altura = 100, 100 #REDIMENSIONAMIENTO DE FOTOGRAFIAS\n",
    "batch_size = 10 # TAMAÑO DE FOTOGRAFIAS A GESTIONAR\n",
    "pasos = 120 #NUMERO DE STEPS PARA ENTRENAMIENTO\n",
    "validation_steps = 80 #NUMERO DE STEPS PARA VALIDACION\n",
    "filtrosConv1 = 32\n",
    "filtrosConv2 = 64\n",
    "tamano_filtro1 = (3, 3)\n",
    "tamano_filtro2 = (2, 2)\n",
    "tamano_pool = (2, 2)\n",
    "clases = 8 #CANTIDAD DE CLASES DE FOTOGRAFIAS A CLASIFICAR\n",
    "lr = 0.0004 #LERANING RATE PARA EL PROCESO DE ENTRENAMIENTO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "5c729a58",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1633 images belonging to 8 classes.\n",
      "Found 810 images belonging to 8 classes.\n"
     ]
    }
   ],
   "source": [
    "#FUNCION IMAGEDATAGENERATOR QUE PROPORCIONARA MODIFICACION A CIERTAS FOTOGRAFIAS PARA OPTIMIZAR EL PROCESO DE ENTRENAMIENTO\n",
    "entrenamiento_datagen = ImageDataGenerator(\n",
    "    rescale=1. / 255,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True)\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale=1. / 255)\n",
    "#FUNCION PARA CONFIGURACION DEL PROCESO DE RECUPERACION DE INFORMACION DE FOTOS PARA ENTRENAMIENTO\n",
    "entrenamiento_generador = entrenamiento_datagen.flow_from_directory(\n",
    "    data_entrenamiento,\n",
    "    target_size=(altura, longitud),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical')\n",
    "#FUNCION PARA CONFIGURACION DEL PROCESO DE RECUPERACION DE INFORMACION DE FOTOS PARA TEST\n",
    "validacion_generador = test_datagen.flow_from_directory(\n",
    "    data_validacion,\n",
    "    target_size=(altura, longitud),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "1dc28601",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#FUNCION PARA EMPEZAR EL MODELO Y SU CONSTRUCCION\n",
    "cnn = Sequential()\n",
    "#PRIMERA CAPA\n",
    "cnn.add(Convolution2D(filtrosConv1, tamano_filtro1, padding =\"same\", input_shape=(longitud, altura, 3), activation='relu'))\n",
    "cnn.add(MaxPooling2D(pool_size=tamano_pool))\n",
    "#SEGUNDA CAPA\n",
    "cnn.add(Convolution2D(filtrosConv2, tamano_filtro2, padding =\"same\"))\n",
    "cnn.add(MaxPooling2D(pool_size=tamano_pool))\n",
    "#RECONFIGURACION DE LA INFORMACION EN DATOS RECONOCIBLES POR EL MODELO\n",
    "cnn.add(Flatten())\n",
    "cnn.add(Dense(256, activation='relu'))\n",
    "cnn.add(Dropout(0.5))\n",
    "cnn.add(Dense(clases, activation='softmax'))\n",
    "#COMPILACION DE LA INFORMACION DENTRO DEL MODELO PARA SU ENTRENAMIENTO \n",
    "cnn.compile(loss='categorical_crossentropy',\n",
    "            optimizer=optimizers.Adam(learning_rate=lr),\n",
    "            metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "34bb2b41",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "120/120 [==============================] - 46s 379ms/step - loss: 1.6260 - accuracy: 0.5532 - val_loss: 1.1597 - val_accuracy: 0.5825\n",
      "Epoch 2/15\n",
      "120/120 [==============================] - 51s 423ms/step - loss: 1.0702 - accuracy: 0.6317 - val_loss: 1.1285 - val_accuracy: 0.6300\n",
      "Epoch 3/15\n",
      "120/120 [==============================] - 48s 402ms/step - loss: 0.8432 - accuracy: 0.7025 - val_loss: 0.6807 - val_accuracy: 0.7700\n",
      "Epoch 4/15\n",
      "120/120 [==============================] - 45s 377ms/step - loss: 0.7258 - accuracy: 0.7485 - val_loss: 1.3052 - val_accuracy: 0.4963\n",
      "Epoch 5/15\n",
      "120/120 [==============================] - 48s 398ms/step - loss: 0.6338 - accuracy: 0.7779 - val_loss: 0.9378 - val_accuracy: 0.6825\n",
      "Epoch 6/15\n",
      "120/120 [==============================] - 48s 400ms/step - loss: 0.6393 - accuracy: 0.7712 - val_loss: 1.0041 - val_accuracy: 0.6200\n",
      "Epoch 7/15\n",
      "120/120 [==============================] - 49s 405ms/step - loss: 0.5510 - accuracy: 0.7921 - val_loss: 0.6091 - val_accuracy: 0.7800\n",
      "Epoch 8/15\n",
      "120/120 [==============================] - 48s 400ms/step - loss: 0.5180 - accuracy: 0.7925 - val_loss: 0.4719 - val_accuracy: 0.8163\n",
      "Epoch 9/15\n",
      "120/120 [==============================] - 50s 416ms/step - loss: 0.4540 - accuracy: 0.8349 - val_loss: 0.6832 - val_accuracy: 0.7675\n",
      "Epoch 10/15\n",
      "120/120 [==============================] - 51s 421ms/step - loss: 0.4262 - accuracy: 0.8550 - val_loss: 0.9657 - val_accuracy: 0.6450\n",
      "Epoch 11/15\n",
      "120/120 [==============================] - 51s 423ms/step - loss: 0.4336 - accuracy: 0.8508 - val_loss: 0.5984 - val_accuracy: 0.7875\n",
      "Epoch 12/15\n",
      "120/120 [==============================] - 55s 455ms/step - loss: 0.4432 - accuracy: 0.8307 - val_loss: 1.2694 - val_accuracy: 0.6288\n",
      "Epoch 13/15\n",
      "120/120 [==============================] - 53s 440ms/step - loss: 0.3643 - accuracy: 0.8592 - val_loss: 1.8541 - val_accuracy: 0.5175\n",
      "Epoch 14/15\n",
      "120/120 [==============================] - 52s 437ms/step - loss: 0.3580 - accuracy: 0.8633 - val_loss: 0.8696 - val_accuracy: 0.7262\n",
      "Epoch 15/15\n",
      "120/120 [==============================] - 53s 443ms/step - loss: 0.3139 - accuracy: 0.8927 - val_loss: 0.8631 - val_accuracy: 0.7638\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2a98f67e8c0>"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#ENTRENAMIENTO DEL MODELO SEGUN LOS DATOS INGRESADOS COMO PARAMETROS\n",
    "cnn.fit(\n",
    "    entrenamiento_generador,\n",
    "    steps_per_epoch=pasos,\n",
    "    epochs=epocas,\n",
    "    validation_data=validacion_generador,\n",
    "    validation_steps=validation_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "406e2057",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#CREACION Y ALMACENAMIENTO DEL RESULTANTE DEL ENTRENAMIENTO PARA RECONOCIMIENTO DE FOTOGRAFIAS\n",
    "target_dir = './modelo/'\n",
    "if not os.path.exists(target_dir):\n",
    "  os.mkdir(target_dir)\n",
    "cnn.save('./modelo/modelo.h5')\n",
    "cnn.save_weights('./modelo/pesos.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "450b9066",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
